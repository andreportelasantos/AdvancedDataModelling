{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Task:\n",
    "\n",
    "Rewrite the previous text classification using bigrams instead of single words.\n",
    "Make sure to filter a bit according to frequency to avoid a huge feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the feature-generation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBinaryVector(review, features):\n",
    "   # the output is a vector of 1's and 0's to indicate whether a word is present in the document\n",
    "    x = []\n",
    "    bigrams = nltk.bigrams(review)\n",
    "    bigrams = set(bigrams)\n",
    "\n",
    "    i = 0\n",
    "    # go through the features (all words)\n",
    "    for bigram in features:\n",
    "        i+=1 \n",
    "        # check whether the word is present\n",
    "        if bigram in bigrams:\n",
    "            x.append(1)\n",
    "        else:\n",
    "            x.append(0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First words of a review: ['the', 'happy', 'bastard', \"'\", 's', 'quick', 'movie', ...]\n",
      "Labels: ['neg', 'pos']\n"
     ]
    }
   ],
   "source": [
    "print(\"First words of a review: \"+str(movie_reviews.words(movie_reviews.fileids()[1])))\n",
    "print(\"Labels: \"+str(movie_reviews.categories()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load reviews and shuffle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [(list(movie_reviews.words(fileid)),category) \n",
    "            for category in movie_reviews.categories() \n",
    "            for fileid in movie_reviews.fileids(category)]\n",
    "reviews = shuffle(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#features: 17602\n"
     ]
    }
   ],
   "source": [
    "# get the features (our words)\n",
    "all_grams = nltk.FreqDist(w for w in nltk.bigrams(movie_reviews.words()))\n",
    "\n",
    "features = {w for w in all_grams.keys() if all_grams[w]>10}\n",
    "print(\"#features: \"+str(len(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the classifier\n",
      "\n",
      "Accuracy is :0.6928571428571428\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for (rev, category) in reviews:\n",
    "    # convert your review into a vector and save it into the feature matrix\n",
    "    X.append(getBinaryVector(rev, features))\n",
    "    \n",
    "    # save the label for your dependent variable list\n",
    "    y.append(category)\n",
    "        \n",
    " # train and test split with sklearn\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7)\n",
    "    \n",
    "# building the classifier\n",
    "print(\"Building the classifier\")\n",
    "nb = GaussianNB()\n",
    "nb_fit = nb.fit(X_train,y_train)\n",
    "\n",
    "# predict based on the test data points\n",
    "y_pred = nb_fit.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "print(\"\\nAccuracy is :\"+str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
