{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Task:\n",
    "\n",
    "Rewrite the previous text classification using bigrams instead of single words.\n",
    "Make sure to filter a bit according to frequency to avoid a huge feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the feature-generation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getBinaryVector(review, features):\n",
    "   # the output is a vector of 1's and 0's to indicate whether a word is present in the document\n",
    "    x = []\n",
    "    # your answer here\n",
    "    \n",
    "   # get the bigrams of the review\n",
    "   # bigrams = ...\n",
    "\n",
    "   # go through the features (all bigrams) and check whether they are in the document\n",
    "   # ...\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First words of a review: ['the', 'happy', 'bastard', \"'\", 's', 'quick', 'movie', ...]\n",
      "Labels: ['neg', 'pos']\n"
     ]
    }
   ],
   "source": [
    "print(\"First words of a review: \"+str(movie_reviews.words(movie_reviews.fileids()[1])))\n",
    "print(\"Labels: \"+str(movie_reviews.categories()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load reviews and shuffle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = [(list(movie_reviews.words(fileid)),category) \n",
    "            for category in movie_reviews.categories() \n",
    "            for fileid in movie_reviews.fileids(category)]\n",
    "reviews = shuffle(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the features\n",
    "\n",
    "Hint: use function ``nltk.FreqDist``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#features: 17602\n"
     ]
    }
   ],
   "source": [
    "# get the features (this time the bigrams)\n",
    "# all_grams = ...\n",
    "\n",
    "# store them according to conditions\n",
    "# features = ...\n",
    "print(\"#features: \"+str(len(features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you go through the modelling procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the classifier\n",
      "\n",
      "Accuracy is :0.64\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for (rev, category) in reviews:\n",
    "    # convert your review into a vector and save it into the feature matrix\n",
    "    X.append(getBinaryVector(rev, features))\n",
    "    \n",
    "    # save the label for your dependent variable list\n",
    "    y.append(category)\n",
    "        \n",
    " # train and test split with sklearn\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7)\n",
    "    \n",
    "# building the classifier\n",
    "print(\"Building the classifier\")\n",
    "nb = GaussianNB()\n",
    "nb_fit = nb.fit(X_train,y_train)\n",
    "\n",
    "# predict based on the test data points\n",
    "y_pred = nb_fit.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "print(\"\\nAccuracy is :\"+str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that your result might be different from the above value, since we did not set a seed at the begining.\n",
    "You may also rerun the code and try.\n",
    "Now recall what we have seen in the previous course, what would you do to get a more robust result?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
