{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text classification with NLTK using Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "NLTK has many built-in functions for text classification. First, we import them. Note that we also import the movie reviews that are included as a corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import movie_reviews\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A list of all the words in 'movie_reviews'\n",
    "movie_reviews.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of words in 'movie_reviews'\n",
    "len(movie_reviews.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First line of a review: \"+str(movie_reviews.words(movie_reviews.fileids()[1])))\n",
    "print(\"Labels: \" + str(movie_reviews.categories()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays frequency of words in ‘movie_reviews’\n",
    "nltk.FreqDist(movie_reviews.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print file ids of positive reviews\n",
    "movie_reviews.fileids('pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all words in movie_review with file id ‘neg/cv001_19502.txt’\n",
    "movie_reviews.words('neg/cv001_19502.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We store the reviews per category as a pair (review, catgeory), in this case the sentiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = [ (list(movie_reviews.words(fileid)), category) \n",
    "            for category in movie_reviews.categories() \n",
    "            for fileid in movie_reviews.fileids(category)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check what they look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"#reviews: \", len(reviews))\n",
    "for (review, category), index in zip(reviews, range(0, len(reviews))):\n",
    "    print('Review ', (index+1), ' first 5 words: ', review[0:5], ' \\tcategory: ', category)\n",
    "    \n",
    "    if index > 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we shuffle them (to avoid having all the negative and positive ones sitting together):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = shuffle(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating features and classification with NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function converts a review into a line of features (i.e. whether a word is present in the review)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getWordVector(document, features):\n",
    "    # only keep a set, the count of the words does not matter\n",
    "    document_words = set(document)\n",
    "    \n",
    "    # create a new list to store the features\n",
    "    doc_features = {}\n",
    "    for word in features:\n",
    "        # if the word is present, True is stored, otherwise, False is stored\n",
    "        doc_features[\"contains_\"+word] = (word in document_words)\n",
    "    return doc_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating features out of text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = [w for w in movie_reviews.words()]\n",
    "all_words = nltk.FreqDist(words)\n",
    "\n",
    "# keep all words that appear more than 200 times (all_words is a dictionary of word - frequency)\n",
    "features = {w for w in all_words.keys() if all_words[w]>200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check feature number\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loop through the reviews and convert the review into a feature vector, store it together with the category\n",
    "featureset = [(getWordVector(rev, features), cat) for (rev, cat) in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "featureset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your training and test set, and train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rudimentary way to split training and test set\n",
    "no_points = round(len(reviews)/2)\n",
    "train, test = featureset[no_points:], featureset[:no_points]\n",
    "\n",
    "# train NB model\n",
    "classifier = nltk.NaiveBayesClassifier.train(train)\n",
    "\n",
    "# print accuracy\n",
    "print(\"Accuracy: \"+str(nltk.classify.accuracy(classifier, test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check whether a function is an interesting feature (based on probability):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for feature in classifier.most_informative_features(n = 20):\n",
    "    print('Interesting feature: ', feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating features and classification with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need some extra libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating one-hot encoding of words (i.e. whether they are present 1 or not 0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getBinaryVector(review, features):\n",
    "    # the output is a vector of 1's and 0's to indicate whether a word is present in the document\n",
    "    x = []\n",
    "    # count does not matter\n",
    "    review = set(review)\n",
    "\n",
    "    # go through the features (all words)\n",
    "    for word in features:\n",
    "       # check whether the word is present\n",
    "        if word in review:\n",
    "            x.append(1)\n",
    "        else:\n",
    "            x.append(0)   \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for (rev, category) in reviews:\n",
    "    # convert your review into a vector and save it into the feature matrix\n",
    "    X.append(getBinaryVector(rev, features))\n",
    "    \n",
    "    # save the label for your dependent variable list\n",
    "    y.append(category)\n",
    "\n",
    "X_df = pd.DataFrame(data = X, columns = features)\n",
    "    \n",
    "# train and test split with sklearn\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y, test_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the classification with naive Bayes and random forests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "rf = RandomForestClassifier()\n",
    "nb_fit = nb.fit(X_train, y_train)\n",
    "rf_fit = rf.fit(X_train, y_train)\n",
    "\n",
    "# predict based on the test data points\n",
    "y_pred = nb_fit.predict(X_test)\n",
    "y_pred_rf = rf_fit.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Accuracy naive Bayes is :\"+str(accuracy))\n",
    "print(\"Accuracy random forest is :\"+str(accuracy_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for feature, importance in zip(X_df.columns, sorted(rf.feature_importances_)):\n",
    "    if importance > 0.005:\n",
    "        print(feature, ' score: \\t', round(importance, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Optional exercise) Instead of Naïve Bayes, try to use SVM.**\n",
    "\n",
    "You may look at the following reference for hints:\n",
    "https://medium.com/@bedigunjit/simple-guide-to-text-classification-nlp-using-svm-and-naive-bayes-with-python-421db3a72d34\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further reference on movie review analysis: \n",
    "https://medium.com/@joel_34096/sentiment-analysis-of-movie-reviews-in-nltk-python-4af4b76a6f3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
