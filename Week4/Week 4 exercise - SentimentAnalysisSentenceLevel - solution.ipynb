{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use NLTK to calculate the sentiment of the following sentences using the average of SentiWordNet, and using VADER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import sentiwordnet as swn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen1 = \"The Harry Potter Series are terribly written and disappointing :(.\"\n",
    "sen2 = \"The Harry Potter Series are brilliant, well written and funny.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SentiWordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function to classify the sentence by using a lemmatiser and tokenizer and SentiWordNet. Return a pair of the overall positive, and the overall negative score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hint 1: Note that the function sentiwordnet needs Synset string\n",
    "sent = swn.senti_synset('nice.a.01')\n",
    "sent.pos_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('cat.n.01'), Synset('guy.n.01'), Synset('cat.n.03'), Synset('kat.n.01'), Synset('cat-o'-nine-tails.n.01'), Synset('caterpillar.n.02'), Synset('big_cat.n.01'), Synset('computerized_tomography.n.01'), Synset('cat.v.01'), Synset('vomit.v.01')]\n",
      "[Synset('cat.n.01'), Synset('guy.n.01'), Synset('cat.n.03'), Synset('kat.n.01'), Synset('cat-o'-nine-tails.n.01'), Synset('caterpillar.n.02'), Synset('big_cat.n.01'), Synset('computerized_tomography.n.01'), Synset('cat.v.01'), Synset('vomit.v.01')]\n"
     ]
    }
   ],
   "source": [
    "print(wn.synsets('cat'))\n",
    "print(wn.synsets('Cats'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Token'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hint 2  with out lemmatizer seems ok, but just to be safe, use wn_lem.lemmatize(token)\n",
    "wn_lem = WordNetLemmatizer()\n",
    "wn_lem.lemmatize('Token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifySentence(sen):\n",
    "    wn_lem = WordNetLemmatizer()\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    for token in nltk.word_tokenize(sen):\n",
    "        lemma = wn_lem.lemmatize(token)\n",
    "        if len(wn.synsets(lemma))>0:\n",
    "            synset = wn.synsets(lemma)[0]\n",
    "            sent = swn.senti_synset(synset.name())\n",
    "            print(\"Sentiment of \"+token+\" \"+str(sent))\n",
    "            pos = pos + sent.pos_score()\n",
    "            neg = neg + sent.neg_score()\n",
    "    return (pos, neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment of Harry <harass.v.01: PosScore=0.0 NegScore=0.125>\n",
      "Sentiment of Potter <potter.n.01: PosScore=0.0 NegScore=0.0>\n",
      "Sentiment of Series <series.n.01: PosScore=0.0 NegScore=0.0>\n",
      "Sentiment of are <are.n.01: PosScore=0.0 NegScore=0.0>\n",
      "Sentiment of terribly <terribly.r.01: PosScore=0.25 NegScore=0.0>\n",
      "Sentiment of written <write.v.01: PosScore=0.0 NegScore=0.0>\n",
      "Sentiment of disappointing <disappoint.v.01: PosScore=0.0 NegScore=0.25>\n",
      "Sen 1: is pos: 0.25 neg: 0.375\n"
     ]
    }
   ],
   "source": [
    "pos, neg = classifySentence(sen1)\n",
    "print(\"Sen 1: is pos: \"+str(pos)+\" neg: \"+str(neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment of Harry <harass.v.01: PosScore=0.0 NegScore=0.125>\n",
      "Sentiment of Potter <potter.n.01: PosScore=0.0 NegScore=0.0>\n",
      "Sentiment of Series <series.n.01: PosScore=0.0 NegScore=0.0>\n",
      "Sentiment of are <are.n.01: PosScore=0.0 NegScore=0.0>\n",
      "Sentiment of brilliant <brilliant.s.01: PosScore=0.875 NegScore=0.0>\n",
      "Sentiment of well <well.n.01: PosScore=0.0 NegScore=0.0>\n",
      "Sentiment of written <write.v.01: PosScore=0.0 NegScore=0.0>\n",
      "Sentiment of funny <funny_story.n.01: PosScore=0.0 NegScore=0.0>\n",
      "Sen 2: is pos: 0.875 neg: 0.125\n"
     ]
    }
   ],
   "source": [
    "pos, neg = classifySentence(sen2)\n",
    "print(\"Sen 2: is pos: \"+str(pos)+\" neg: \"+str(neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VADER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, do the same using VADER (also return the compound score, computed by normalizing the scores above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "sid = SIA()\n",
    "\n",
    "def classifySentenceVADER(sen):\n",
    "    ss = sid.polarity_scores(sen) \n",
    "    print(ss)\n",
    "    return (ss['pos'], ss['neg'], ss['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.459, 'neu': 0.541, 'pos': 0.0, 'compound': -0.7783}\n",
      "Sen 1: is pos: 0.0 neg: 0.459  overall:  -0.7783\n"
     ]
    }
   ],
   "source": [
    "pos, neg, comp = classifySentenceVADER(sen1)\n",
    "print(\"Sen 1: is pos: \"+str(pos)+\" neg: \"+str(neg), \" overall: \", str(comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.443, 'pos': 0.557, 'compound': 0.8316}\n",
      "Sen 2: is pos: 0.557 neg: 0.0  overall:  0.8316\n"
     ]
    }
   ],
   "source": [
    "pos, neg, comp = classifySentenceVADER(sen2)\n",
    "print(\"Sen 2: is pos: \"+str(pos)+\" neg: \"+str(neg), \" overall: \", str(comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.459, 'neu': 0.541, 'pos': 0.0, 'compound': -0.7783}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#or a more direct way\n",
    "sid.polarity_scores(sen1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
