{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook:\n",
    "1. How to use ``WordNet``\n",
    "2. Path similarity and Lin similarity\n",
    "3. How to use ``SentiWordNet``\n",
    "4. How to use ``VADER``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Using WordNet (NLTK)\n",
    "\n",
    "Check the following websites if you want to know more ``WordNet``\n",
    "\n",
    "Tutorial on Youtube\n",
    "- https://www.youtube.com/watch?v=T68P5-8tM-Y\n",
    "\n",
    "A step-by-step walk-through analysis\n",
    "- https://nlpforhackers.io/sentiment-analysis-intro/\n",
    "\n",
    "``wordnet.synsets`` documentation\n",
    "- http://www.nltk.org/api/nltk.corpus.reader.html?highlight=wordnet#nltk.corpus.reader.wordnet.Lemma.synset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first time running, download the 'sentiwordnet' package by running the following comment\n",
    "# nltk.download('sentiwordnet')\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import sentiwordnet as swn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's see some basic operations using wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('good.n.01'), Synset('good.n.02'), Synset('good.n.03'), Synset('commodity.n.01'), Synset('good.a.01'), Synset('full.s.06'), Synset('good.a.03'), Synset('estimable.s.02'), Synset('beneficial.s.01'), Synset('good.s.06'), Synset('good.s.07'), Synset('adept.s.01'), Synset('good.s.09'), Synset('dear.s.02'), Synset('dependable.s.04'), Synset('good.s.12'), Synset('good.s.13'), Synset('effective.s.04'), Synset('good.s.15'), Synset('good.s.16'), Synset('good.s.17'), Synset('good.s.18'), Synset('good.s.19'), Synset('good.s.20'), Synset('good.s.21'), Synset('well.r.01'), Synset('thoroughly.r.02')]\n",
      "\n",
      " The 0-th element: good\n"
     ]
    }
   ],
   "source": [
    "# list of a wordnet synset for word 'good'\n",
    "syns_wn = wn.synsets('good')\n",
    "print(syns_wn)\n",
    "# only the word of the 0-th element\n",
    "print('\\n The 0-th element:',syns_wn[0].lemmas()[0].name()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benefit\n",
      "['for your own good', \"what's the good of worrying?\"]\n"
     ]
    }
   ],
   "source": [
    "# Check word's definition\n",
    "print(syns_wn[0].definition())\n",
    "# Sentence examples\n",
    "print(syns_wn[0].examples())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some relations are defined by WordNet only over Lemmas, see https://www.nltk.org/howto/wordnet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('nasty.a.01.nasty')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('nice.a.01').lemmas()[0].antonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('nasty.a.01.nasty')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or another way\n",
    "wn.lemmas('nice')[1].antonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Nice',\n",
       " 'courteous',\n",
       " 'dainty',\n",
       " 'decent',\n",
       " 'gracious',\n",
       " 'nice',\n",
       " 'overnice',\n",
       " 'prissy',\n",
       " 'skillful',\n",
       " 'squeamish'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set of synonyms of the word 'nice'\n",
    "synonym = []\n",
    "for w in wn.synsets('nice'):\n",
    "    for l in w.lemmas():\n",
    "        synonym.append(l.name())\n",
    "    \n",
    "set(synonym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "0.5\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# comparing words' similarity\n",
    "w1 = wn.synset('phone.n.01')\n",
    "w2 = wn.synset('computer.n.01')\n",
    "print(w1.wup_similarity(w2))\n",
    "# or print(wn.wup_similarity(w1, w2))\n",
    "\n",
    "w1 = wn.synset('bad.a.01')\n",
    "w2 = wn.synset('regretful.a.01')\n",
    "print(w1.wup_similarity(w2))\n",
    "\n",
    "\n",
    "w1 = wn.synset('have.v.01')\n",
    "w2 = wn.synset('own.v.01')\n",
    "print(w1.wup_similarity(w2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the adjectives in ``WordNet`` are not arranged in a hierarchy, so shortest path will not work with adjectives. \n",
    "You might get 'None' when comparing two adjectives. The same for adverbs.\n",
    "See http://wn-similarity.sourceforge.net/ for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text similarity\n",
    "\n",
    "### Path similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "w1 = wn.synset('dog.n.01')\n",
    "w2 = wn.synset('corgi.n.01')\n",
    "print(wn.path_similarity(w1, w2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lin similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8768009843733973\n"
     ]
    }
   ],
   "source": [
    "# first we need to create an information content dictionary from a corpus \n",
    "from nltk.corpus import wordnet_ic\n",
    "brown_ic = wordnet_ic.ic('ic-brown.dat') #use brown corpus\n",
    "\n",
    "w1 = wn.synset('dog.n.01')\n",
    "w2 = wn.synset('cat.n.01')\n",
    "print(wn.lin_similarity(w1,w2, brown_ic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8043806652422293\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import genesis\n",
    "genesis_ic = wn.ic(genesis, False, 0.0)\n",
    "print(wn.lin_similarity(w1,w2, genesis_ic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "\n",
    "## 3. Using SentiWordNet (NLTK)\n",
    "\n",
    "One of the most straightforward approaches is to use SentiWordnet to compute the polarity of the words and average that value.  Now let's see how to use ``SentiWordnet``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('good.n.01'), Synset('good.n.02'), Synset('good.n.03'), Synset('commodity.n.01'), Synset('good.a.01'), Synset('full.s.06'), Synset('good.a.03'), Synset('estimable.s.02'), Synset('beneficial.s.01'), Synset('good.s.06'), Synset('good.s.07'), Synset('adept.s.01'), Synset('good.s.09'), Synset('dear.s.02'), Synset('dependable.s.04'), Synset('good.s.12'), Synset('good.s.13'), Synset('effective.s.04'), Synset('good.s.15'), Synset('good.s.16'), Synset('good.s.17'), Synset('good.s.18'), Synset('good.s.19'), Synset('good.s.20'), Synset('good.s.21'), Synset('well.r.01'), Synset('thoroughly.r.02')]\n"
     ]
    }
   ],
   "source": [
    "# recall the WordNet synsets for the word 'good'\n",
    "print(wn.synsets('good'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now check the synonym set using ``SentiWordnet``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/sentiwordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SentiSynset('good.n.01'),\n",
       " SentiSynset('good.n.02'),\n",
       " SentiSynset('good.n.03'),\n",
       " SentiSynset('commodity.n.01'),\n",
       " SentiSynset('good.a.01'),\n",
       " SentiSynset('full.s.06'),\n",
       " SentiSynset('good.a.03'),\n",
       " SentiSynset('estimable.s.02'),\n",
       " SentiSynset('beneficial.s.01'),\n",
       " SentiSynset('good.s.06'),\n",
       " SentiSynset('good.s.07'),\n",
       " SentiSynset('adept.s.01'),\n",
       " SentiSynset('good.s.09'),\n",
       " SentiSynset('dear.s.02'),\n",
       " SentiSynset('dependable.s.04'),\n",
       " SentiSynset('good.s.12'),\n",
       " SentiSynset('good.s.13'),\n",
       " SentiSynset('effective.s.04'),\n",
       " SentiSynset('good.s.15'),\n",
       " SentiSynset('good.s.16'),\n",
       " SentiSynset('good.s.17'),\n",
       " SentiSynset('good.s.18'),\n",
       " SentiSynset('good.s.19'),\n",
       " SentiSynset('good.s.20'),\n",
       " SentiSynset('good.s.21'),\n",
       " SentiSynset('well.r.01'),\n",
       " SentiSynset('thoroughly.r.02')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of a sentiwordnet synset of the word 'good'\n",
    "nltk.download('sentiwordnet')\n",
    "syns_swn = swn.senti_synsets('good')\n",
    "list(syns_swn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SentiSynset('good.a.01'),\n",
       " SentiSynset('full.s.06'),\n",
       " SentiSynset('good.a.03'),\n",
       " SentiSynset('estimable.s.02'),\n",
       " SentiSynset('beneficial.s.01')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synset_filter = swn.senti_synsets('good','a') # you may specify variable type, as adjective\n",
    "synset_list = list(synset_filter)\n",
    "synset_list[:5] # check the first 5 elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SentiWordNet assigns to each synset of WordNet three\n",
    "sentiment scores: positivity, negativity, and objectivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# positivity score\n",
    "swn.senti_synset('good.a.01').pos_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# negativity score\n",
    "swn.senti_synset('good.a.01').neg_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# objectivity score\n",
    "swn.senti_synset('good.a.01').obj_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful characteristics of a synset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " benefit\n",
      "[Lemma('good.n.01.good')]\n",
      "Pos: 0.5 neg: 0.0\n",
      "\n",
      " moral excellence or admirableness\n",
      "[Lemma('good.n.02.good'), Lemma('good.n.02.goodness')]\n",
      "Pos: 0.875 neg: 0.0\n",
      "\n",
      " that which is pleasing or valuable or useful\n",
      "[Lemma('good.n.03.good'), Lemma('good.n.03.goodness')]\n",
      "Pos: 0.625 neg: 0.0\n",
      "\n",
      " articles of commerce\n",
      "[Lemma('commodity.n.01.commodity'), Lemma('commodity.n.01.trade_good'), Lemma('commodity.n.01.good')]\n",
      "Pos: 0.0 neg: 0.0\n",
      "\n",
      " having desirable or positive qualities especially those suitable for a thing specified\n",
      "[Lemma('good.a.01.good')]\n",
      "Pos: 0.75 neg: 0.0\n",
      "\n",
      " having the normally expected amount\n",
      "[Lemma('full.s.06.full'), Lemma('full.s.06.good')]\n",
      "Pos: 0.0 neg: 0.0\n",
      "\n",
      " morally admirable\n",
      "[Lemma('good.a.03.good')]\n",
      "Pos: 1.0 neg: 0.0\n",
      "\n",
      " deserving of esteem and respect\n",
      "[Lemma('estimable.s.02.estimable'), Lemma('estimable.s.02.good'), Lemma('estimable.s.02.honorable'), Lemma('estimable.s.02.respectable')]\n",
      "Pos: 1.0 neg: 0.0\n",
      "\n",
      " promoting or enhancing well-being\n",
      "[Lemma('beneficial.s.01.beneficial'), Lemma('beneficial.s.01.good')]\n",
      "Pos: 0.625 neg: 0.0\n",
      "\n",
      " agreeable or pleasing\n",
      "[Lemma('good.s.06.good')]\n",
      "Pos: 1.0 neg: 0.0\n",
      "\n",
      " of moral excellence\n",
      "[Lemma('good.s.07.good'), Lemma('good.s.07.just'), Lemma('good.s.07.upright')]\n",
      "Pos: 0.75 neg: 0.0\n",
      "\n",
      " having or showing knowledge and skill and aptitude\n",
      "[Lemma('adept.s.01.adept'), Lemma('adept.s.01.expert'), Lemma('adept.s.01.good'), Lemma('adept.s.01.practiced'), Lemma('adept.s.01.proficient'), Lemma('adept.s.01.skillful'), Lemma('adept.s.01.skilful')]\n",
      "Pos: 0.625 neg: 0.0\n",
      "\n",
      " thorough\n",
      "[Lemma('good.s.09.good')]\n",
      "Pos: 0.625 neg: 0.0\n",
      "\n",
      " with or in a close or intimate relationship\n",
      "[Lemma('dear.s.02.dear'), Lemma('dear.s.02.good'), Lemma('dear.s.02.near')]\n",
      "Pos: 0.5 neg: 0.0\n",
      "\n",
      " financially sound\n",
      "[Lemma('dependable.s.04.dependable'), Lemma('dependable.s.04.good'), Lemma('dependable.s.04.safe'), Lemma('dependable.s.04.secure')]\n",
      "Pos: 0.5 neg: 0.0\n",
      "\n",
      " most suitable or right for a particular purpose\n",
      "[Lemma('good.s.12.good'), Lemma('good.s.12.right'), Lemma('good.s.12.ripe')]\n",
      "Pos: 0.375 neg: 0.0\n",
      "\n",
      " resulting favorably\n",
      "[Lemma('good.s.13.good'), Lemma('good.s.13.well')]\n",
      "Pos: 0.625 neg: 0.0\n",
      "\n",
      " exerting force or influence\n",
      "[Lemma('effective.s.04.effective'), Lemma('effective.s.04.good'), Lemma('effective.s.04.in_effect'), Lemma('effective.s.04.in_force')]\n",
      "Pos: 0.0 neg: 0.0\n",
      "\n",
      " capable of pleasing\n",
      "[Lemma('good.s.15.good')]\n",
      "Pos: 0.625 neg: 0.0\n",
      "\n",
      " appealing to the mind\n",
      "[Lemma('good.s.16.good'), Lemma('good.s.16.serious')]\n",
      "Pos: 0.75 neg: 0.0\n",
      "\n",
      " in excellent physical condition\n",
      "[Lemma('good.s.17.good'), Lemma('good.s.17.sound')]\n",
      "Pos: 0.75 neg: 0.0\n",
      "\n",
      " tending to promote physical well-being; beneficial to health\n",
      "[Lemma('good.s.18.good'), Lemma('good.s.18.salutary')]\n",
      "Pos: 0.875 neg: 0.0\n",
      "\n",
      " not forged\n",
      "[Lemma('good.s.19.good'), Lemma('good.s.19.honest')]\n",
      "Pos: 0.5 neg: 0.0\n",
      "\n",
      " not left to spoil\n",
      "[Lemma('good.s.20.good'), Lemma('good.s.20.undecomposed'), Lemma('good.s.20.unspoiled'), Lemma('good.s.20.unspoilt')]\n",
      "Pos: 0.375 neg: 0.125\n",
      "\n",
      " generally admired\n",
      "[Lemma('good.s.21.good')]\n",
      "Pos: 0.75 neg: 0.0\n",
      "\n",
      " (often used as a combining form) in a good or proper or satisfactory manner or to a high standard (`good' is a nonstandard dialectal variant for `well')\n",
      "[Lemma('well.r.01.well'), Lemma('well.r.01.good')]\n",
      "Pos: 0.375 neg: 0.0\n",
      "\n",
      " completely and absolutely (`good' is sometimes used informally for `thoroughly')\n",
      "[Lemma('thoroughly.r.02.thoroughly'), Lemma('thoroughly.r.02.soundly'), Lemma('thoroughly.r.02.good')]\n",
      "Pos: 0.0 neg: 0.0\n"
     ]
    }
   ],
   "source": [
    "good_syns = swn.senti_synsets('good')\n",
    "\n",
    "for good_sentisyn in good_syns:\n",
    "    good_synset = good_sentisyn.synset\n",
    "    print(\"\\n\", good_synset.definition())\n",
    "    print(good_synset.lemmas())\n",
    "    print(\"Pos: \"+str(good_sentisyn.pos_score())+\" neg: \"+str(good_sentisyn.neg_score()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### 4. Using Valence Aware Dictionary and sEntiment Reasoner (VADER)\n",
    "\n",
    "Another function for calculating Polarity, even in sentence level\n",
    "\n",
    "-``SentimentIntensityAnalyzer()`` Documentation\n",
    "http://www.nltk.org/howto/sentiment.html\n",
    "\n",
    "-``VADER`` demostration\n",
    "https://towardsdatascience.com/sentimental-analysis-using-vader-a3415fef7664\n",
    "\n",
    "Note:\n",
    "The score ``compound`` is computed by normalizing the scores ``negative``, ``neutral`` and ``positive`` obtained from VADERâ€™s ``SentimentIntensityAnalyzer()``.\n",
    "\n",
    "More detailes see https://towardsdatascience.com/sentimental-analysis-using-vader-a3415fef7664"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.608, 'neu': 0.392, 'pos': 0.0, 'compound': -0.4767}\n",
      "Delivery was terrible.  is overall negative  -0.4767\n",
      "{'neg': 0.315, 'neu': 0.685, 'pos': 0.0, 'compound': -0.3182}\n",
      "Media and web analytics is boring.  is overall negative  -0.3182\n",
      "{'neg': 0.0, 'neu': 0.609, 'pos': 0.391, 'compound': 0.6696}\n",
      "M&WA is the best course in the world!  is overall positive  0.6696\n",
      "{'neg': 0.0, 'neu': 0.625, 'pos': 0.375, 'compound': 0.6369}\n",
      "M&WA is the best course in the world  is overall positive  0.6369\n"
     ]
    }
   ],
   "source": [
    "sentences=[\"Delivery was terrible.\"\n",
    "           , \"Media and web analytics is boring.\"\n",
    "           , \"M&WA is the best course in the world!\"\n",
    "           , \"M&WA is the best course in the world\"]\n",
    "\n",
    "# Create a sentiment intensity analyzer object:\n",
    "sid = SIA()\n",
    "\n",
    "# Loop the sentences\n",
    "for sentence in sentences:\n",
    "    ss = sid.polarity_scores(sentence) \n",
    "    print(ss)\n",
    "    if ss['compound'] < 0:\n",
    "        print(sentence, ' is overall negative ', ss['compound'])\n",
    "    elif ss['compound'] == 0:\n",
    "        print(sentence, ' is overall neutral')\n",
    "    else:\n",
    "        print(sentence, ' is overall positive ', ss['compound'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some more examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's cool.  is overall positive  0.3182\n",
      "That's quite cool.  is overall positive  0.3804\n",
      "That's cool :)  is overall positive  0.6486\n",
      "That's super cool :)  is overall positive  0.8481\n"
     ]
    }
   ],
   "source": [
    "sentences=[\"That's cool.\"\n",
    "           , \"That's quite cool.\"\n",
    "           , \"That's cool :)\"\n",
    "           , \"That's super cool :)\"]\n",
    "\n",
    "sid = SIA()\n",
    "\n",
    "# Loop the sentences\n",
    "for sentence in sentences:\n",
    "    ss = sid.polarity_scores(sentence) \n",
    "    if ss['compound'] < 0:\n",
    "        print(sentence, ' is overall negative ', ss['compound'])\n",
    "    elif ss['compound'] == 0:\n",
    "        print(sentence, ' is overall neutral')\n",
    "    else:\n",
    "        print(sentence, ' is overall positive ', ss['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
